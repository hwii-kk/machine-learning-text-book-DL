{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"chap17-2.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOyC4uXeboCd63oNCJAyBVK"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"d6796efba7404df3af47944601457979":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_139c581b36bb42e8a359d2c6b98ba9c5","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_8ea990a8872c44a99dac7dcc6d9ac440","IPY_MODEL_5ba994a8415b49f086b618f7996bd4fb","IPY_MODEL_441d273e69fe4fdfbe9a25cb4ad5324c"]}},"139c581b36bb42e8a359d2c6b98ba9c5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8ea990a8872c44a99dac7dcc6d9ac440":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_214568ca355d41888a7bb1da1b755865","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Dl Completed...: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_9424f503bc014d44ab7765a95b1c9c1e"}},"5ba994a8415b49f086b618f7996bd4fb":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_f5461cf6744747b3870964866b4babbc","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":4,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":4,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_463d1164b0e24dc1ab41321dbcea402f"}},"441d273e69fe4fdfbe9a25cb4ad5324c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_5236331be778409698dcd8b48d33d14d","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 4/4 [00:00&lt;00:00, 12.38 file/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_15274b95d278439fb917d01341ac5b63"}},"214568ca355d41888a7bb1da1b755865":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"9424f503bc014d44ab7765a95b1c9c1e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f5461cf6744747b3870964866b4babbc":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"463d1164b0e24dc1ab41321dbcea402f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5236331be778409698dcd8b48d33d14d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"15274b95d278439fb917d01341ac5b63":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","source":["# Setting"],"metadata":{"id":"1Cn8RUXPKBHV"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vuqb5yYPJx5X","executionInfo":{"status":"ok","timestamp":1641890699027,"user_tz":-540,"elapsed":20699,"user":{"displayName":"Hwisung Kwon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gizs2pMSWME6appADm19iw3b0G9f_CCWjKda6cL=s64","userId":"05107164275958408212"}},"outputId":"21532d8d-710f-44b7-fffc-8c251da97437"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"]},{"cell_type":"code","source":["import sys\n","from IPython.display import Image\n","import matplotlib\n","%matplotlib inline\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import numpy as np\n","import seaborn as sns\n","import os\n","import warnings\n","import tensorflow as tf\n","import tensorflow_datasets as tfds\n","warnings.filterwarnings(\"ignore\")"],"metadata":{"id":"V5FNbB83KCO9","executionInfo":{"status":"ok","timestamp":1641890702213,"user_tz":-540,"elapsed":3190,"user":{"displayName":"Hwisung Kwon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gizs2pMSWME6appADm19iw3b0G9f_CCWjKda6cL=s64","userId":"05107164275958408212"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["# 17.3 합성곱 GAN과 바서슈타인 GAN으로 합성 이미지 품질 높이기"],"metadata":{"id":"Dy186q5gKNBW"}},{"cell_type":"markdown","source":["GAN 예제의 성능을 높이기 위해 DCGAN을 만들어 보겠다.\n","\n","몇 가지 중요한 기술을 도입하고 바서슈타인 GAN을 구현해 보겠다.\n","\n","전치 합성곱, 배치 정규화, WGAN, 그레이디언트 페널티"],"metadata":{"id":"LIJmFU9eKRwB"}},{"cell_type":"markdown","source":["## 17.3.1 전치 합성곱"],"metadata":{"id":"sVhxboesKjXC"}},{"cell_type":"markdown","source":["합성곱 연산은 보통 특성 맵을 다운샘플링하지만 전치 합성곱 연산은 특성 맵을 업샘플링하는 데 사용한다.\n","\n","합성곱 연산을 통해 출력 특성 맵을 만들고 원래 크기의 특성 맵을 얻는 합성곱을 적용하여도 행렬의 크기는 복원되지만 실제 행렬 값은 복원되지 않는다."],"metadata":{"id":"c4OQG1F0Kl2D"}},{"cell_type":"code","source":["Image(url='https://git.io/JLjn7', width=700)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":267},"id":"s05Y8LdeLQ78","executionInfo":{"status":"ok","timestamp":1641890702214,"user_tz":-540,"elapsed":14,"user":{"displayName":"Hwisung Kwon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gizs2pMSWME6appADm19iw3b0G9f_CCWjKda6cL=s64","userId":"05107164275958408212"}},"outputId":"c425c4d5-11bd-4a80-b7d6-23801e8253da"},"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/html":["<img src=\"https://git.io/JLjn7\" width=\"700\"/>"],"text/plain":["<IPython.core.display.Image object>"]},"metadata":{},"execution_count":3}]},{"cell_type":"markdown","source":["전치 합성곱은 입력 특성 맵의 원소 사이에 0을 끼워 넣어 합성곱을 수행하는 식으로 특성 맵을 업샘플링한다."],"metadata":{"id":"ZpJb3_s-LiaA"}},{"cell_type":"code","source":["Image(url='https://git.io/JLjnb', width=700)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":360},"id":"cNfP_W7OMk2l","executionInfo":{"status":"ok","timestamp":1641890702214,"user_tz":-540,"elapsed":9,"user":{"displayName":"Hwisung Kwon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gizs2pMSWME6appADm19iw3b0G9f_CCWjKda6cL=s64","userId":"05107164275958408212"}},"outputId":"e5688c2b-e9e7-46a8-dd94-7b7c8f2f08dc"},"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/html":["<img src=\"https://git.io/JLjnb\" width=\"700\"/>"],"text/plain":["<IPython.core.display.Image object>"]},"metadata":{},"execution_count":4}]},{"cell_type":"markdown","source":["## 17.3.2 배치 정규화"],"metadata":{"id":"SixRCzzcLweH"}},{"cell_type":"markdown","source":["배치 정규화의 주요 아이디어 중 하나는 층의 입력을 정규화하고 훈련하는 동안 입력 분포의 변화를 막는 것이다.\n","\n","이는 모델을 빠르고 안정적으로 수렴하게 만든다.\n","\n","배치 정규화는 계산된 통계 값을 기반으로 미니 배치의 특성을 변환한다.\n","\n","배치 정규화 단계를 정리해보면\n","\n","1. 미니 배치 입력의 평균과 표준편차를 계산한다.\n","\n","2. 배치에 있는 모든 샘플의 입력을 표준화한다.\n","\n","3. 정규화된 입력을 학습하는 두 개의 파라미터 백터로 스케일을 조정하고 이동시킨다."],"metadata":{"id":"hg0dfL8ZLyHt"}},{"cell_type":"code","source":["Image(url='https://git.io/JLjnA', width=700)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":478},"id":"YVDAHGL6Mygn","executionInfo":{"status":"ok","timestamp":1641890702215,"user_tz":-540,"elapsed":9,"user":{"displayName":"Hwisung Kwon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gizs2pMSWME6appADm19iw3b0G9f_CCWjKda6cL=s64","userId":"05107164275958408212"}},"outputId":"c3df8389-3a11-49d3-9a90-5df10080676e"},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/html":["<img src=\"https://git.io/JLjnA\" width=\"700\"/>"],"text/plain":["<IPython.core.display.Image object>"]},"metadata":{},"execution_count":5}]},{"cell_type":"markdown","source":["표준화된 입력 값을 가지면 경사 하강법 기반의 최적화 방식에 바람직한 성질이다.\n","\n","반면 각기 다른 미니 배치에서 동일한 성질을 같도록 항상 입력을 정규화하면 신경망의 표현 능력에 큰 영향을 미칠 수 있다.\n","\n","표준정규분포를 따르는 변수가 시그모이드 함수를 통과할 때 0에 가까운 값은 선형적인 영역이기 때문이다.\n","\n","따라서 단계 3에서 크기가 c인 학습 가능한 파라미터를 이용하여 정규화된 특성을 이동시키고 분산시킨다.\n","\n","훈련한느 동안 이동 평균과 이동 분산을 계산하는데 이 값은 튜닝 파라미터와 함께 사용하여 평가 시에 테스트 샘플을 정규화한다.\n","\n","배치 정규화가 최적화에 도움이 되는 이유는 초기에 배치 정규화는 내부 공변량 변화를 감소하기 위해 개발되었는데 내부 공변량 변화는 신경망이 훈련하는 동안 모델 파라미터가 업데이트되기 때문에 층 활성화의 분산에 변화가 생기는 현상이다."],"metadata":{"id":"KeM9XBSEM0XE"}},{"cell_type":"markdown","source":["## 17.3.3 생성자와 판별자 구현"],"metadata":{"id":"_ZxxuLH3Nnl_"}},{"cell_type":"code","source":["#생성자\n","\n","Image(url='https://git.io/JLjnx', width=700)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":310},"id":"BntD-tBYOodt","executionInfo":{"status":"ok","timestamp":1641890702215,"user_tz":-540,"elapsed":8,"user":{"displayName":"Hwisung Kwon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gizs2pMSWME6appADm19iw3b0G9f_CCWjKda6cL=s64","userId":"05107164275958408212"}},"outputId":"869b1271-558d-4886-ecc5-378638903226"},"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/html":["<img src=\"https://git.io/JLjnx\" width=\"700\"/>"],"text/plain":["<IPython.core.display.Image object>"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["#판별자\n","\n","Image(url='https://git.io/JLjnj', width=700)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":385},"id":"TnmYa3B9OpiV","executionInfo":{"status":"ok","timestamp":1641890702628,"user_tz":-540,"elapsed":12,"user":{"displayName":"Hwisung Kwon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gizs2pMSWME6appADm19iw3b0G9f_CCWjKda6cL=s64","userId":"05107164275958408212"}},"outputId":"5baf5177-dfc6-47f4-d58c-d7981efb5c15"},"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/html":["<img src=\"https://git.io/JLjnj\" width=\"700\"/>"],"text/plain":["<IPython.core.display.Image object>"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["import tensorflow as tf\n","\n","\n","print(tf.__version__)\n","\n","print(\"GPU 여부:\", len(tf.config.list_physical_devices('GPU')) > 0)\n","\n","if tf.config.list_physical_devices('GPU'):\n","    device_name = tf.test.gpu_device_name()\n","else:\n","    device_name = 'CPU:0'\n","    \n","print(device_name)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fDT4U8B0TyuF","executionInfo":{"status":"ok","timestamp":1641890705420,"user_tz":-540,"elapsed":2801,"user":{"displayName":"Hwisung Kwon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gizs2pMSWME6appADm19iw3b0G9f_CCWjKda6cL=s64","userId":"05107164275958408212"}},"outputId":"8b8ff5c2-e4e9-4ffa-8896-c45cda5909bb"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["2.7.0\n","GPU 여부: True\n","/device:GPU:0\n"]}]},{"cell_type":"code","source":["def make_dcgan_generator(\n","        z_size=20, \n","        output_size=(28, 28, 1),\n","        n_filters=128, \n","        n_blocks=2):\n","    size_factor = 2**n_blocks\n","    hidden_size = (\n","        output_size[0]//size_factor, \n","        output_size[1]//size_factor\n","    )\n","    \n","    model = tf.keras.Sequential([\n","        tf.keras.layers.Input(shape=(z_size,)),\n","        \n","        tf.keras.layers.Dense(\n","            units=n_filters*np.prod(hidden_size), \n","            use_bias=False),\n","        tf.keras.layers.BatchNormalization(),\n","        tf.keras.layers.LeakyReLU(),\n","        tf.keras.layers.Reshape(\n","            (hidden_size[0], hidden_size[1], n_filters)),\n","    \n","        tf.keras.layers.Conv2DTranspose(\n","            filters=n_filters, kernel_size=(5, 5), strides=(1, 1),\n","            padding='same', use_bias=False),\n","        tf.keras.layers.BatchNormalization(),\n","        tf.keras.layers.LeakyReLU()\n","    ])\n","        \n","    nf = n_filters\n","    for i in range(n_blocks):\n","        nf = nf // 2\n","        model.add(\n","            tf.keras.layers.Conv2DTranspose(\n","                filters=nf, kernel_size=(5, 5), strides=(2, 2),\n","                padding='same', use_bias=False))\n","        model.add(tf.keras.layers.BatchNormalization())\n","        model.add(tf.keras.layers.LeakyReLU())\n","                \n","    model.add(\n","        tf.keras.layers.Conv2DTranspose(\n","            filters=output_size[2], kernel_size=(5, 5), \n","            strides=(1, 1), padding='same', use_bias=False, \n","            activation='tanh'))\n","        \n","    return model\n","\n","def make_dcgan_discriminator(\n","        input_size=(28, 28, 1),\n","        n_filters=64, \n","        n_blocks=2):\n","    model = tf.keras.Sequential([\n","        tf.keras.layers.Input(shape=input_size),\n","        tf.keras.layers.Conv2D(\n","            filters=n_filters, kernel_size=5, \n","            strides=(1, 1), padding='same'),\n","        tf.keras.layers.BatchNormalization(),\n","        tf.keras.layers.LeakyReLU()\n","    ])\n","    \n","    nf = n_filters\n","    for i in range(n_blocks):\n","        nf = nf*2\n","        model.add(\n","            tf.keras.layers.Conv2D(\n","                filters=nf, kernel_size=(5, 5), \n","                strides=(2, 2),padding='same'))\n","        model.add(tf.keras.layers.BatchNormalization())\n","        model.add(tf.keras.layers.LeakyReLU())\n","        model.add(tf.keras.layers.Dropout(0.3))\n","        \n","    model.add(tf.keras.layers.Conv2D(\n","            filters=1, kernel_size=(7, 7), padding='valid'))\n","    \n","    model.add(tf.keras.layers.Reshape((1,)))\n","    \n","    return model"],"metadata":{"id":"QlKUx5i9OsMT","executionInfo":{"status":"ok","timestamp":1641890705421,"user_tz":-540,"elapsed":5,"user":{"displayName":"Hwisung Kwon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gizs2pMSWME6appADm19iw3b0G9f_CCWjKda6cL=s64","userId":"05107164275958408212"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["gen_model = make_dcgan_generator()\n","gen_model.summary()\n","\n","disc_model = make_dcgan_discriminator()\n","disc_model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"54cuo0ulPbyp","executionInfo":{"status":"ok","timestamp":1641890705843,"user_tz":-540,"elapsed":426,"user":{"displayName":"Hwisung Kwon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gizs2pMSWME6appADm19iw3b0G9f_CCWjKda6cL=s64","userId":"05107164275958408212"}},"outputId":"aa30b4b2-552d-4f7f-d9ac-90504ab38226"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense (Dense)               (None, 6272)              125440    \n","                                                                 \n"," batch_normalization (BatchN  (None, 6272)             25088     \n"," ormalization)                                                   \n","                                                                 \n"," leaky_re_lu (LeakyReLU)     (None, 6272)              0         \n","                                                                 \n"," reshape (Reshape)           (None, 7, 7, 128)         0         \n","                                                                 \n"," conv2d_transpose (Conv2DTra  (None, 7, 7, 128)        409600    \n"," nspose)                                                         \n","                                                                 \n"," batch_normalization_1 (Batc  (None, 7, 7, 128)        512       \n"," hNormalization)                                                 \n","                                                                 \n"," leaky_re_lu_1 (LeakyReLU)   (None, 7, 7, 128)         0         \n","                                                                 \n"," conv2d_transpose_1 (Conv2DT  (None, 14, 14, 64)       204800    \n"," ranspose)                                                       \n","                                                                 \n"," batch_normalization_2 (Batc  (None, 14, 14, 64)       256       \n"," hNormalization)                                                 \n","                                                                 \n"," leaky_re_lu_2 (LeakyReLU)   (None, 14, 14, 64)        0         \n","                                                                 \n"," conv2d_transpose_2 (Conv2DT  (None, 28, 28, 32)       51200     \n"," ranspose)                                                       \n","                                                                 \n"," batch_normalization_3 (Batc  (None, 28, 28, 32)       128       \n"," hNormalization)                                                 \n","                                                                 \n"," leaky_re_lu_3 (LeakyReLU)   (None, 28, 28, 32)        0         \n","                                                                 \n"," conv2d_transpose_3 (Conv2DT  (None, 28, 28, 1)        800       \n"," ranspose)                                                       \n","                                                                 \n","=================================================================\n","Total params: 817,824\n","Trainable params: 804,832\n","Non-trainable params: 12,992\n","_________________________________________________________________\n","Model: \"sequential_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d (Conv2D)             (None, 28, 28, 64)        1664      \n","                                                                 \n"," batch_normalization_4 (Batc  (None, 28, 28, 64)       256       \n"," hNormalization)                                                 \n","                                                                 \n"," leaky_re_lu_4 (LeakyReLU)   (None, 28, 28, 64)        0         \n","                                                                 \n"," conv2d_1 (Conv2D)           (None, 14, 14, 128)       204928    \n","                                                                 \n"," batch_normalization_5 (Batc  (None, 14, 14, 128)      512       \n"," hNormalization)                                                 \n","                                                                 \n"," leaky_re_lu_5 (LeakyReLU)   (None, 14, 14, 128)       0         \n","                                                                 \n"," dropout (Dropout)           (None, 14, 14, 128)       0         \n","                                                                 \n"," conv2d_2 (Conv2D)           (None, 7, 7, 256)         819456    \n","                                                                 \n"," batch_normalization_6 (Batc  (None, 7, 7, 256)        1024      \n"," hNormalization)                                                 \n","                                                                 \n"," leaky_re_lu_6 (LeakyReLU)   (None, 7, 7, 256)         0         \n","                                                                 \n"," dropout_1 (Dropout)         (None, 7, 7, 256)         0         \n","                                                                 \n"," conv2d_3 (Conv2D)           (None, 1, 1, 1)           12545     \n","                                                                 \n"," reshape_1 (Reshape)         (None, 1)                 0         \n","                                                                 \n","=================================================================\n","Total params: 1,040,385\n","Trainable params: 1,039,489\n","Non-trainable params: 896\n","_________________________________________________________________\n"]}]},{"cell_type":"markdown","source":["## 17.3.4 두 분포 사이의 거리 측정"],"metadata":{"id":"Bx2N2IINPdF3"}},{"cell_type":"markdown","source":["생성자 모델은 훈련 데이터셋과 같은 분포를 가진 새로운 샘플을 합성하는 법을 배우는 것이 목적이다.\n","\n"],"metadata":{"id":"xmxjSTdBPtGC"}},{"cell_type":"code","source":["Image(url='https://git.io/JLjcf', width=700)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":355},"id":"AB1e51dxP4Df","executionInfo":{"status":"ok","timestamp":1641890705845,"user_tz":-540,"elapsed":18,"user":{"displayName":"Hwisung Kwon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gizs2pMSWME6appADm19iw3b0G9f_CCWjKda6cL=s64","userId":"05107164275958408212"}},"outputId":"e96a92de-51f9-4708-a42a-22f340169561"},"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/html":["<img src=\"https://git.io/JLjcf\" width=\"700\"/>"],"text/plain":["<IPython.core.display.Image object>"]},"metadata":{},"execution_count":11}]},{"cell_type":"markdown","source":["- TV 거리 : 각 포인트에서 두 분산 사이의 가장 큰 차이\n","\n","- EM 거리 : 한 분포에서 다른 분포로 변환할 때 필요한 최소의 작업량이다.\n","\n","- KL,JS \n"],"metadata":{"id":"eassRBkGP4Mf"}},{"cell_type":"code","source":["Image(url='https://git.io/JLjcJ', width=800)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":553},"id":"16P2pcYaQTq8","executionInfo":{"status":"ok","timestamp":1641890705846,"user_tz":-540,"elapsed":15,"user":{"displayName":"Hwisung Kwon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gizs2pMSWME6appADm19iw3b0G9f_CCWjKda6cL=s64","userId":"05107164275958408212"}},"outputId":"3770ff37-4eaa-4cc4-fa46-1510749eb9a2"},"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/html":["<img src=\"https://git.io/JLjcJ\" width=\"800\"/>"],"text/plain":["<IPython.core.display.Image object>"]},"metadata":{},"execution_count":12}]},{"cell_type":"markdown","source":["원본 GAN에 있는 손실 함수는 진짜와 가짜 샘플 사이의 JS 발산을 최소화하는 것임을 수학적으로 증명할 수 있다.\n","\n","하지만 JS 발산은 GAN 모델 훈련을 할 때 문제가 있다.\n","\n","따라서 훈련 성능을 높이기 위해 연구자들은 EM 거리를 진짜와 가짜 샘플 분포 사이의 거리를 측정하는 데 사용했다.\n","\n","EM 거리를 계산하는 것은 그 자체가 최적화 문제이다. \n","\n","따라서 계산하기가 매우 어렵다.\n","\n","다행히 EM 거리 계산을 칸트로비치-루빈스타인 쌍대성 이론을 사용해 단순화할 수 있다."],"metadata":{"id":"fC-rm5F6QVc_"}},{"cell_type":"markdown","source":["## 17.3.5 GAN에 EM 거리 사용"],"metadata":{"id":"-TFxbX5aRw8p"}},{"cell_type":"markdown","source":["문제는 진짜와 가짜 샘플 사이의 바서슈타인 거리를 계산하기 위한 1-립시츠 함수를 어떻게 찾느냐는 것이다.\n","\n","심층 신경망이 어떤 함수도 근사할 수 있다.\n","\n","기본 GAN은 판별자를 분류기 형태로 사용한다.\n","\n","WGAN에서는 판별자를 바꾸어 확률 점수 대신에 스칼라 점수를 반환하는 비평자로 바꿀 수 있다.\n","\n","이 점수를 입력 이미지가 얼마나 진짜 같은지 나타내는 정도로 해석할 수 있다.\n","\n"],"metadata":{"id":"DyByxidjRzVI"}},{"cell_type":"markdown","source":["## 17.3.6 그레이디언트 페널티"],"metadata":{"id":"U7bfkNbbTF1P"}},{"cell_type":"markdown","source":["1. 한 배치에서 진짜와 가짜 샘플의 각 쌍에 대해 균등 분포에서 랜덤한 수를 샘플링한다.\n","\n","2. 진짜와 가짜 샘플 사이를 보간한다. 결국 보간된 샘플의 배치가 만들어진다.\n","\n","3. 보간된 전체 샘플에 대해 판별자 출력을 계산한다.\n","\n","4. 각 보간된 샘플에 대해 비평자 출력의 그레이디언트를 계산한다.\n","\n","5. GP를 계산."],"metadata":{"id":"ydA1H5CITIQJ"}},{"cell_type":"code","source":["mnist_bldr = tfds.builder('mnist')\n","mnist_bldr.download_and_prepare()\n","mnist = mnist_bldr.as_dataset(shuffle_files=False)\n","\n","def preprocess(ex, mode='uniform'):\n","    image = ex['image']\n","    image = tf.image.convert_image_dtype(image, tf.float32)\n","\n","    image = image*2 - 1.0\n","    if mode == 'uniform':\n","        input_z = tf.random.uniform(\n","            shape=(z_size,), minval=-1.0, maxval=1.0)\n","    elif mode == 'normal':\n","        input_z = tf.random.normal(shape=(z_size,))\n","    return input_z, image"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":194,"referenced_widgets":["d6796efba7404df3af47944601457979","139c581b36bb42e8a359d2c6b98ba9c5","8ea990a8872c44a99dac7dcc6d9ac440","5ba994a8415b49f086b618f7996bd4fb","441d273e69fe4fdfbe9a25cb4ad5324c","214568ca355d41888a7bb1da1b755865","9424f503bc014d44ab7765a95b1c9c1e","f5461cf6744747b3870964866b4babbc","463d1164b0e24dc1ab41321dbcea402f","5236331be778409698dcd8b48d33d14d","15274b95d278439fb917d01341ac5b63"]},"id":"spieJYk3TYz2","executionInfo":{"status":"ok","timestamp":1641890707032,"user_tz":-540,"elapsed":1198,"user":{"displayName":"Hwisung Kwon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gizs2pMSWME6appADm19iw3b0G9f_CCWjKda6cL=s64","userId":"05107164275958408212"}},"outputId":"4b2ef7fa-4bbf-4067-a420-4c3fb9a60997"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1mDownloading and preparing dataset mnist/3.0.1 (download: 11.06 MiB, generated: 21.00 MiB, total: 32.06 MiB) to /root/tensorflow_datasets/mnist/3.0.1...\u001b[0m\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Dataset mnist is hosted on GCS. It will automatically be downloaded to your\n","local data directory. If you'd instead prefer to read directly from our public\n","GCS bucket (recommended if you're running on GCP), you can instead pass\n","`try_gcs=True` to `tfds.load` or set `data_dir=gs://tfds-data/datasets`.\n","\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d6796efba7404df3af47944601457979","version_minor":0,"version_major":2},"text/plain":["Dl Completed...:   0%|          | 0/4 [00:00<?, ? file/s]"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","\u001b[1mDataset mnist downloaded and prepared to /root/tensorflow_datasets/mnist/3.0.1. Subsequent calls will reuse this data.\u001b[0m\n"]}]},{"cell_type":"code","source":["num_epochs = 100\n","batch_size = 128\n","image_size = (28, 28)\n","z_size = 20\n","mode_z = 'uniform'\n","lambda_gp = 10.0\n","\n","tf.random.set_seed(1)\n","np.random.seed(1)\n","\n","## 데이터셋 준비\n","mnist_trainset = mnist['train']\n","mnist_trainset = mnist_trainset.map(preprocess)\n","\n","mnist_trainset = mnist_trainset.shuffle(10000)\n","mnist_trainset = mnist_trainset.batch(\n","    batch_size, drop_remainder=True)\n","\n","## 모델 생성\n","with tf.device(device_name):\n","    gen_model = make_dcgan_generator()\n","    gen_model.build(input_shape=(None, z_size))\n","    gen_model.summary()\n","\n","    disc_model = make_dcgan_discriminator()\n","    disc_model.build(input_shape=(None, np.prod(image_size)))\n","    disc_model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jShTs36YTjel","executionInfo":{"status":"ok","timestamp":1641890707781,"user_tz":-540,"elapsed":755,"user":{"displayName":"Hwisung Kwon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gizs2pMSWME6appADm19iw3b0G9f_CCWjKda6cL=s64","userId":"05107164275958408212"}},"outputId":"d8472e3c-78fa-46c1-b4e6-19d314cd6dc0"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_2\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_1 (Dense)             (None, 6272)              125440    \n","                                                                 \n"," batch_normalization_7 (Batc  (None, 6272)             25088     \n"," hNormalization)                                                 \n","                                                                 \n"," leaky_re_lu_7 (LeakyReLU)   (None, 6272)              0         \n","                                                                 \n"," reshape_2 (Reshape)         (None, 7, 7, 128)         0         \n","                                                                 \n"," conv2d_transpose_4 (Conv2DT  (None, 7, 7, 128)        409600    \n"," ranspose)                                                       \n","                                                                 \n"," batch_normalization_8 (Batc  (None, 7, 7, 128)        512       \n"," hNormalization)                                                 \n","                                                                 \n"," leaky_re_lu_8 (LeakyReLU)   (None, 7, 7, 128)         0         \n","                                                                 \n"," conv2d_transpose_5 (Conv2DT  (None, 14, 14, 64)       204800    \n"," ranspose)                                                       \n","                                                                 \n"," batch_normalization_9 (Batc  (None, 14, 14, 64)       256       \n"," hNormalization)                                                 \n","                                                                 \n"," leaky_re_lu_9 (LeakyReLU)   (None, 14, 14, 64)        0         \n","                                                                 \n"," conv2d_transpose_6 (Conv2DT  (None, 28, 28, 32)       51200     \n"," ranspose)                                                       \n","                                                                 \n"," batch_normalization_10 (Bat  (None, 28, 28, 32)       128       \n"," chNormalization)                                                \n","                                                                 \n"," leaky_re_lu_10 (LeakyReLU)  (None, 28, 28, 32)        0         \n","                                                                 \n"," conv2d_transpose_7 (Conv2DT  (None, 28, 28, 1)        800       \n"," ranspose)                                                       \n","                                                                 \n","=================================================================\n","Total params: 817,824\n","Trainable params: 804,832\n","Non-trainable params: 12,992\n","_________________________________________________________________\n","Model: \"sequential_3\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d_4 (Conv2D)           (None, 28, 28, 64)        1664      \n","                                                                 \n"," batch_normalization_11 (Bat  (None, 28, 28, 64)       256       \n"," chNormalization)                                                \n","                                                                 \n"," leaky_re_lu_11 (LeakyReLU)  (None, 28, 28, 64)        0         \n","                                                                 \n"," conv2d_5 (Conv2D)           (None, 14, 14, 128)       204928    \n","                                                                 \n"," batch_normalization_12 (Bat  (None, 14, 14, 128)      512       \n"," chNormalization)                                                \n","                                                                 \n"," leaky_re_lu_12 (LeakyReLU)  (None, 14, 14, 128)       0         \n","                                                                 \n"," dropout_2 (Dropout)         (None, 14, 14, 128)       0         \n","                                                                 \n"," conv2d_6 (Conv2D)           (None, 7, 7, 256)         819456    \n","                                                                 \n"," batch_normalization_13 (Bat  (None, 7, 7, 256)        1024      \n"," chNormalization)                                                \n","                                                                 \n"," leaky_re_lu_13 (LeakyReLU)  (None, 7, 7, 256)         0         \n","                                                                 \n"," dropout_3 (Dropout)         (None, 7, 7, 256)         0         \n","                                                                 \n"," conv2d_7 (Conv2D)           (None, 1, 1, 1)           12545     \n","                                                                 \n"," reshape_3 (Reshape)         (None, 1)                 0         \n","                                                                 \n","=================================================================\n","Total params: 1,040,385\n","Trainable params: 1,039,489\n","Non-trainable params: 896\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["import time\n","\n","\n","## 옵티마이저:\n","g_optimizer = tf.keras.optimizers.Adam(0.0002)\n","d_optimizer = tf.keras.optimizers.Adam(0.0002)\n","\n","if mode_z == 'uniform':\n","    fixed_z = tf.random.uniform(\n","        shape=(batch_size, z_size),\n","        minval=-1, maxval=1)\n","elif mode_z == 'normal':\n","    fixed_z = tf.random.normal(\n","        shape=(batch_size, z_size))\n","\n","def create_samples(g_model, input_z):\n","    g_output = g_model(input_z, training=False)\n","    images = tf.reshape(g_output, (batch_size, *image_size))    \n","    return (images+1)/2.0\n","\n","all_losses = []\n","epoch_samples = []\n","\n","start_time = time.time()\n","\n","for epoch in range(1, num_epochs+1):\n","    epoch_losses = []\n","    for i,(input_z,input_real) in enumerate(mnist_trainset):\n","        \n","        with tf.GradientTape() as d_tape, tf.GradientTape() as g_tape:\n","            g_output = gen_model(input_z, training=True)\n","            \n","            d_critics_real = disc_model(input_real, training=True)\n","            d_critics_fake = disc_model(g_output, training=True)\n","\n","            ## 생성자 손실을 계산합니다:\n","            g_loss = -tf.math.reduce_mean(d_critics_fake)\n","\n","            ## 판별자 손실을 계산합니다:\n","            d_loss_real = -tf.math.reduce_mean(d_critics_real)\n","            d_loss_fake =  tf.math.reduce_mean(d_critics_fake)\n","            d_loss = d_loss_real + d_loss_fake\n","\n","            ## 그래디언트 페널티:\n","            with tf.GradientTape() as gp_tape:\n","                alpha = tf.random.uniform(\n","                    shape=[d_critics_real.shape[0], 1, 1, 1], \n","                    minval=0.0, maxval=1.0)\n","                interpolated = (\n","                    alpha*input_real + (1-alpha)*g_output)\n","                gp_tape.watch(interpolated)\n","                d_critics_intp = disc_model(interpolated)\n","            \n","            grads_intp = gp_tape.gradient(\n","                d_critics_intp, [interpolated,])[0]\n","            grads_intp_l2 = tf.sqrt(\n","                tf.reduce_sum(tf.square(grads_intp), axis=[1, 2, 3]))\n","            grad_penalty = tf.reduce_mean(tf.square(grads_intp_l2 - 1.0))\n","        \n","            d_loss = d_loss + lambda_gp*grad_penalty\n","        \n","        ## 최적화: 그래디언트를 계산하고 적용합니다\n","        d_grads = d_tape.gradient(d_loss, disc_model.trainable_variables)\n","        d_optimizer.apply_gradients(\n","            grads_and_vars=zip(d_grads, disc_model.trainable_variables))\n","        \n","        g_grads = g_tape.gradient(g_loss, gen_model.trainable_variables)\n","        g_optimizer.apply_gradients(\n","            grads_and_vars=zip(g_grads, gen_model.trainable_variables))\n","\n","        epoch_losses.append(\n","            (g_loss.numpy(), d_loss.numpy(), \n","             d_loss_real.numpy(), d_loss_fake.numpy()))\n","                    \n","    all_losses.append(epoch_losses)\n","    \n","    print('에포크 {:-3d} | 시간 {:.2f} min | 평균 손실 >>'\n","          ' 생성자/판별자 {:6.2f}/{:6.2f} [판별자-진짜: {:6.2f} 판별자-가짜: {:6.2f}]'\n","          .format(epoch, (time.time() - start_time)/60, \n","                  *list(np.mean(all_losses[-1], axis=0)))\n","    )\n","    \n","    epoch_samples.append(\n","        create_samples(gen_model, fixed_z).numpy()\n","    )"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"SooAttVeTr24","executionInfo":{"status":"error","timestamp":1641902630872,"user_tz":-540,"elapsed":11883873,"user":{"displayName":"Hwisung Kwon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gizs2pMSWME6appADm19iw3b0G9f_CCWjKda6cL=s64","userId":"05107164275958408212"}},"outputId":"dac724a8-f3f1-4518-bd49-e8f26e06ed56"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["에포크   1 | 시간 3.66 min | 평균 손실 >> 생성자/판별자 264.35/-429.40 [판별자-진짜: -267.40 판별자-가짜: -264.35]\n","에포크   2 | 시간 7.07 min | 평균 손실 >> 생성자/판별자 196.05/-171.74 [판별자-진짜: -117.04 판별자-가짜: -196.05]\n","에포크   3 | 시간 10.47 min | 평균 손실 >> 생성자/판별자 177.99/-95.76 [판별자-진짜: -71.55 판별자-가짜: -177.99]\n","에포크   4 | 시간 13.89 min | 평균 손실 >> 생성자/판별자 153.67/  7.65 [판별자-진짜:   8.30 판별자-가짜: -153.67]\n","에포크   5 | 시간 17.28 min | 평균 손실 >> 생성자/판별자  87.47/ 12.47 [판별자-진짜:   9.40 판별자-가짜: -87.47]\n","에포크   6 | 시간 20.70 min | 평균 손실 >> 생성자/판별자  77.16/-22.17 [판별자-진짜:   7.99 판별자-가짜: -77.16]\n","에포크   7 | 시간 24.09 min | 평균 손실 >> 생성자/판별자  69.26/ -9.35 [판별자-진짜:  13.11 판별자-가짜: -69.26]\n","에포크   8 | 시간 27.51 min | 평균 손실 >> 생성자/판별자  62.45/-19.28 [판별자-진짜:  18.93 판별자-가짜: -62.45]\n","에포크   9 | 시간 30.90 min | 평균 손실 >> 생성자/판별자  87.78/-39.11 [판별자-진짜:  37.20 판별자-가짜: -87.78]\n","에포크  10 | 시간 34.33 min | 평균 손실 >> 생성자/판별자  64.18/-33.13 [판별자-진짜:  19.21 판별자-가짜: -64.18]\n","에포크  11 | 시간 37.75 min | 평균 손실 >> 생성자/판별자  82.42/-38.13 [판별자-진짜:  34.49 판별자-가짜: -82.42]\n","에포크  12 | 시간 41.18 min | 평균 손실 >> 생성자/판별자  67.78/-52.19 [판별자-진짜:   0.74 판별자-가짜: -67.78]\n","에포크  13 | 시간 44.59 min | 평균 손실 >> 생성자/판별자 110.75/-53.14 [판별자-진짜:  40.66 판별자-가짜: -110.75]\n","에포크  14 | 시간 48.02 min | 평균 손실 >> 생성자/판별자  77.70/-41.94 [판별자-진짜:  17.53 판별자-가짜: -77.70]\n","에포크  15 | 시간 51.41 min | 평균 손실 >> 생성자/판별자 118.16/-33.35 [판별자-진짜:  72.45 판별자-가짜: -118.16]\n","에포크  16 | 시간 54.82 min | 평균 손실 >> 생성자/판별자 115.43/-15.83 [판별자-진짜:  77.42 판별자-가짜: -115.43]\n","에포크  17 | 시간 58.21 min | 평균 손실 >> 생성자/판별자 106.63/-51.91 [판별자-진짜:  46.40 판별자-가짜: -106.63]\n","에포크  18 | 시간 61.63 min | 평균 손실 >> 생성자/판별자 113.43/-30.58 [판별자-진짜:  72.31 판별자-가짜: -113.43]\n","에포크  19 | 시간 65.02 min | 평균 손실 >> 생성자/판별자 149.71/-43.61 [판별자-진짜:  95.57 판별자-가짜: -149.71]\n","에포크  20 | 시간 68.44 min | 평균 손실 >> 생성자/판별자 121.57/-30.98 [판별자-진짜:  71.69 판별자-가짜: -121.57]\n","에포크  21 | 시간 71.84 min | 평균 손실 >> 생성자/판별자 151.26/-31.43 [판별자-진짜: 110.17 판별자-가짜: -151.26]\n","에포크  22 | 시간 75.25 min | 평균 손실 >> 생성자/판별자 158.16/-31.47 [판별자-진짜: 116.23 판별자-가짜: -158.16]\n","에포크  23 | 시간 78.63 min | 평균 손실 >> 생성자/판별자  98.24/-40.41 [판별자-진짜:  46.27 판별자-가짜: -98.24]\n","에포크  24 | 시간 82.04 min | 평균 손실 >> 생성자/판별자 190.15/-44.54 [판별자-진짜: 129.51 판별자-가짜: -190.15]\n","에포크  25 | 시간 85.43 min | 평균 손실 >> 생성자/판별자 136.93/-42.37 [판별자-진짜:  81.85 판별자-가짜: -136.93]\n","에포크  26 | 시간 88.84 min | 평균 손실 >> 생성자/판별자 133.19/-42.77 [판별자-진짜:  76.03 판별자-가짜: -133.19]\n","에포크  27 | 시간 93.20 min | 평균 손실 >> 생성자/판별자 155.59/-44.99 [판별자-진짜:  94.99 판별자-가짜: -155.59]\n","에포크  28 | 시간 96.63 min | 평균 손실 >> 생성자/판별자 177.70/-47.63 [판별자-진짜: 114.92 판별자-가짜: -177.70]\n","에포크  29 | 시간 100.03 min | 평균 손실 >> 생성자/판별자 173.38/-43.70 [판별자-진짜: 105.07 판별자-가짜: -173.38]\n","에포크  30 | 시간 103.45 min | 평균 손실 >> 생성자/판별자 199.71/-41.55 [판별자-진짜: 144.40 판별자-가짜: -199.71]\n","에포크  31 | 시간 106.84 min | 평균 손실 >> 생성자/판별자 211.30/-43.73 [판별자-진짜: 158.55 판별자-가짜: -211.30]\n","에포크  32 | 시간 110.26 min | 평균 손실 >> 생성자/판별자 239.02/ -9.22 [판별자-진짜: 188.39 판별자-가짜: -239.02]\n","에포크  33 | 시간 113.65 min | 평균 손실 >> 생성자/판별자 227.56/-46.30 [판별자-진짜: 174.08 판별자-가짜: -227.56]\n","에포크  34 | 시간 117.06 min | 평균 손실 >> 생성자/판별자 250.82/-42.74 [판별자-진짜: 204.08 판별자-가짜: -250.82]\n","에포크  35 | 시간 120.45 min | 평균 손실 >> 생성자/판별자 225.22/-46.13 [판별자-진짜: 167.38 판별자-가짜: -225.22]\n","에포크  36 | 시간 123.86 min | 평균 손실 >> 생성자/판별자 207.33/-16.32 [판별자-진짜: 153.90 판별자-가짜: -207.33]\n","에포크  37 | 시간 127.23 min | 평균 손실 >> 생성자/판별자 253.02/-49.98 [판별자-진짜: 188.87 판별자-가짜: -253.02]\n","에포크  38 | 시간 130.63 min | 평균 손실 >> 생성자/판별자 275.91/-45.16 [판별자-진짜: 218.75 판별자-가짜: -275.91]\n","에포크  39 | 시간 134.01 min | 평균 손실 >> 생성자/판별자 259.90/-59.22 [판별자-진짜: 186.09 판별자-가짜: -259.90]\n","에포크  40 | 시간 137.41 min | 평균 손실 >> 생성자/판별자 198.40/-52.75 [판별자-진짜: 134.41 판별자-가짜: -198.40]\n","에포크  41 | 시간 140.79 min | 평균 손실 >> 생성자/판별자 279.07/-51.02 [판별자-진짜: 210.30 판별자-가짜: -279.07]\n","에포크  42 | 시간 144.20 min | 평균 손실 >> 생성자/판별자 266.68/-45.93 [판별자-진짜: 208.62 판별자-가짜: -266.68]\n","에포크  43 | 시간 147.60 min | 평균 손실 >> 생성자/판별자 187.90/-47.64 [판별자-진짜: 123.42 판별자-가짜: -187.90]\n","에포크  44 | 시간 151.05 min | 평균 손실 >> 생성자/판별자 217.72/ -0.89 [판별자-진짜: 176.46 판별자-가짜: -217.72]\n","에포크  45 | 시간 154.47 min | 평균 손실 >> 생성자/판별자 166.02/-41.52 [판별자-진짜: 117.06 판별자-가짜: -166.02]\n","에포크  46 | 시간 157.92 min | 평균 손실 >> 생성자/판별자 158.93/-50.72 [판별자-진짜:  96.26 판별자-가짜: -158.93]\n","에포크  47 | 시간 161.34 min | 평균 손실 >> 생성자/판별자 194.74/-49.66 [판별자-진짜: 128.03 판별자-가짜: -194.74]\n","에포크  48 | 시간 164.78 min | 평균 손실 >> 생성자/판별자 259.18/-36.74 [판별자-진짜: 195.02 판별자-가짜: -259.18]\n","에포크  49 | 시간 168.20 min | 평균 손실 >> 생성자/판별자 288.24/-58.61 [판별자-진짜: 219.76 판별자-가짜: -288.24]\n","에포크  50 | 시간 171.65 min | 평균 손실 >> 생성자/판별자 287.06/-59.31 [판별자-진짜: 216.44 판별자-가짜: -287.06]\n","에포크  51 | 시간 175.07 min | 평균 손실 >> 생성자/판별자  47.94/-36.89 [판별자-진짜:   3.27 판별자-가짜: -47.94]\n","에포크  52 | 시간 178.52 min | 평균 손실 >> 생성자/판별자 250.76/-42.74 [판별자-진짜: 166.32 판별자-가짜: -250.76]\n","에포크  53 | 시간 181.95 min | 평균 손실 >> 생성자/판별자 184.77/-48.68 [판별자-진짜: 121.65 판별자-가짜: -184.77]\n","에포크  54 | 시간 185.42 min | 평균 손실 >> 생성자/판별자 221.16/-54.29 [판별자-진짜: 143.93 판별자-가짜: -221.16]\n","에포크  55 | 시간 188.85 min | 평균 손실 >> 생성자/판별자 272.33/-68.09 [판별자-진짜: 186.28 판별자-가짜: -272.33]\n","에포크  56 | 시간 192.32 min | 평균 손실 >> 생성자/판별자 281.56/-55.73 [판별자-진짜: 220.12 판별자-가짜: -281.56]\n","에포크  57 | 시간 195.75 min | 평균 손실 >> 생성자/판별자 442.63/-71.52 [판별자-진짜: 358.56 판별자-가짜: -442.63]\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-15-6141e9c8264f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;31m## 최적화: 그래디언트를 계산하고 적용합니다\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0md_grads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md_tape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisc_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         d_optimizer.apply_gradients(\n\u001b[1;32m     65\u001b[0m             grads_and_vars=zip(d_grads, disc_model.trainable_variables))\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m   1088\u001b[0m         \u001b[0moutput_gradients\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1089\u001b[0m         \u001b[0msources_raw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflat_sources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1090\u001b[0;31m         unconnected_gradients=unconnected_gradients)\n\u001b[0m\u001b[1;32m   1091\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1092\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_persistent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[0;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[1;32m     75\u001b[0m       \u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m       \u001b[0msources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m       compat.as_str(unconnected_gradients.value))\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36m_gradient_function\u001b[0;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001b[0m\n\u001b[1;32m    157\u001b[0m       \u001b[0mgradient_name_scope\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mforward_pass_name_scope\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradient_name_scope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/nn_grad.py\u001b[0m in \u001b[0;36m_Conv2DGrad\u001b[0;34m(op, grad)\u001b[0m\n\u001b[1;32m    588\u001b[0m           \u001b[0mexplicit_paddings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexplicit_paddings\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m           \u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 590\u001b[0;31m           data_format=data_format),\n\u001b[0m\u001b[1;32m    591\u001b[0m       gen_nn_ops.conv2d_backprop_filter(\n\u001b[1;32m    592\u001b[0m           \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_nn_ops.py\u001b[0m in \u001b[0;36mconv2d_backprop_input\u001b[0;34m(input_sizes, filter, out_backprop, strides, padding, use_cudnn_on_gpu, explicit_paddings, data_format, dilations, name)\u001b[0m\n\u001b[1;32m   1242\u001b[0m         \u001b[0;34m\"strides\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"use_cudnn_on_gpu\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"padding\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1243\u001b[0m         \u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"explicit_paddings\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexplicit_paddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"data_format\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1244\u001b[0;31m         data_format, \"dilations\", dilations)\n\u001b[0m\u001b[1;32m   1245\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1246\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["#합성 샘플의 품질이 어떻게 바뀌는지 보자\n","import itertools\n","\n","\n","fig = plt.figure(figsize=(8, 6))\n","\n","## 손실 그래프\n","ax = fig.add_subplot(1, 1, 1)\n","g_losses = [item[0] for item in itertools.chain(*all_losses)]\n","d_losses = [item[1] for item in itertools.chain(*all_losses)]\n","plt.plot(g_losses, label='Generator loss', alpha=0.95)\n","plt.plot(d_losses, label='Discriminator loss', alpha=0.95)\n","plt.legend(fontsize=20)\n","ax.set_xlabel('Iteration', size=15)\n","ax.set_ylabel('Loss', size=15)\n","\n","epochs = np.arange(1, 101)\n","epoch2iter = lambda e: e*len(all_losses[-1])\n","epoch_ticks = [1, 20, 40, 60, 80, 100]\n","newpos   = [epoch2iter(e) for e in epoch_ticks]\n","ax2 = ax.twiny()\n","ax2.set_xticks(newpos)\n","ax2.set_xticklabels(epoch_ticks)\n","ax2.xaxis.set_ticks_position('bottom')\n","ax2.xaxis.set_label_position('bottom')\n","ax2.spines['bottom'].set_position(('outward', 60))\n","ax2.set_xlabel('Epoch', size=15)\n","ax2.set_xlim(ax.get_xlim())\n","ax.tick_params(axis='both', which='major', labelsize=15)\n","ax2.tick_params(axis='both', which='major', labelsize=15)\n","\n","plt.show()"],"metadata":{"id":"s1gt5HL4UJEI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["selected_epochs = [1, 2, 4, 10, 50, 100]\n","fig = plt.figure(figsize=(10, 14))\n","for i,e in enumerate(selected_epochs):\n","    for j in range(5):\n","        ax = fig.add_subplot(6, 5, i*5+j+1)\n","        ax.set_xticks([])\n","        ax.set_yticks([])\n","        if j == 0:\n","            ax.text(\n","                -0.06, 0.5, 'Epoch {}'.format(e),\n","                rotation=90, size=18, color='red',\n","                horizontalalignment='right',\n","                verticalalignment='center', \n","                transform=ax.transAxes)\n","        \n","        image = epoch_samples[e-1][j]\n","        ax.imshow(image, cmap='gray_r')\n","\n","plt.show()"],"metadata":{"id":"b2yMb_v4dlwC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 17.3.8 모드 붕괴"],"metadata":{"id":"jvjRHOFDUSZ3"}},{"cell_type":"markdown","source":["GAN은 적대적인 특징 때문에 훈련하기 어렵기로 악명이 높다.\n","\n","실패하는 흔한 이유 중 하나는 생성자가 작은 부분 공간에 갇혀 단순한 샘플만 생성하는 것을 학습할 때이다.\n","\n","이를 모드 붕괴라고 부른다.\n","\n","그레이디언트 폭주와 소멸 문제 외에도 GAN 훈련을 어렵게 만들 수 있는 또 다른 면이 있다.\n","\n","전문가들이 권장하는 몇 가지 기법이 있다.\n","\n","하나는 미니 배치 판별이다.\n","\n","가짜나 진짜 샘플로만 이루어진 배치를 따로 판별자에게 주입한다.\n","\n","미니 배치 판별에서는 판별자가 배치가 진짜인지 가짜인지 판단하기 위해 배치 안의 샘플을 비교한다.\n","\n","만약 모델이 모드 붕괴 문제를 겪고 있다면 진짜 샘플로만 구성된 배치가 가짜 배치보다 다양성이 높을 것이다.\n","\n","안정적인 GAN 훈련을 위해 널리 사용하는 또 다른 기법은 특성 매칭이다.\n","\n","특성 매칭에서는 생성자의 목적 함수를 조금 수정한다.\n","\n","판별자의 중간 표현을 기반으로 원본 이미지와 합성 이미지 간의 차이를 최소화하는 추가적인 항을 더한다."],"metadata":{"id":"8W9RV3_1UVUL"}},{"cell_type":"code","source":["Image(url='https://git.io/JLjcT', width=600)"],"metadata":{"id":"sx3Xvc0Jdoy7"},"execution_count":null,"outputs":[]}]}