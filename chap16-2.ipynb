{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"chap16-2.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPcsU7w50ttTjGCBvIdyiN4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Setting"],"metadata":{"id":"zZJCgm1_i4JL"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gZnGcIArjP5R","executionInfo":{"status":"ok","timestamp":1641609525387,"user_tz":-540,"elapsed":19375,"user":{"displayName":"Hwisung Kwon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gizs2pMSWME6appADm19iw3b0G9f_CCWjKda6cL=s64","userId":"05107164275958408212"}},"outputId":"54d89355-6d6b-456f-816d-f8f77e35ce8c"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["import sys\n","from IPython.display import Image\n","import matplotlib\n","%matplotlib inline\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import numpy as np\n","import seaborn as sns\n","import os\n","import warnings\n","import tensorflow as tf\n","import tensorflow_datasets as tfds\n","warnings.filterwarnings(\"ignore\")"],"metadata":{"id":"ifQDrrs2jQxu","executionInfo":{"status":"ok","timestamp":1641609613766,"user_tz":-540,"elapsed":3180,"user":{"displayName":"Hwisung Kwon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gizs2pMSWME6appADm19iw3b0G9f_CCWjKda6cL=s64","userId":"05107164275958408212"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["os.chdir('/content/drive/My Drive/Colab Notebooks/머신러닝 교과서/data')"],"metadata":{"id":"Fm_46Kx9lsz8","executionInfo":{"status":"ok","timestamp":1641610190443,"user_tz":-540,"elapsed":298,"user":{"displayName":"Hwisung Kwon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gizs2pMSWME6appADm19iw3b0G9f_CCWjKda6cL=s64","userId":"05107164275958408212"}}},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":["## 16.3.2 두 번째 프로젝트 : 텐서플로로 글자 단위의 언어 모델 구현"],"metadata":{"id":"rppw84GgjsE2"}},{"cell_type":"markdown","source":["언어 모델링은 영어 문장 생성처럼 기계가 사람의 언어와 관련된 작업을 수행하도록 하는 흥미로운 애플리케이션이다.\n","\n","이 분야에서 관심을 끄는 결과물 중 하나는 서스키버, 마틴, 힌튼의 작업이다.\n","\n","앞으로 만들 모델의 입력은 텍스트 문서이다.\n","\n","입력 문서와 비슷한 스타일로 새로운 텍스트를 생성하는 모델을 만드는 것이 목표이다.\n","\n","글자 단위 언어 모델링에서 입력은 글자의 시퀀스로 나누어 한 번에 글자 하나씩 네트워크에 주입된다.\n","\n","이 네트워크는 지금까지 본 글자와 함께 새로운 글자를 처리하여 다음 글자를 예측한다."],"metadata":{"id":"5Hefadw9jwXy"}},{"cell_type":"code","source":["Image(url='https://git.io/JLdVE', width=700)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":238},"id":"om8CU6g5kLd_","executionInfo":{"status":"ok","timestamp":1641609745200,"user_tz":-540,"elapsed":317,"user":{"displayName":"Hwisung Kwon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gizs2pMSWME6appADm19iw3b0G9f_CCWjKda6cL=s64","userId":"05107164275958408212"}},"outputId":"4563cbf7-ad1d-40b8-d0de-6d030f769bdb"},"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/html":["<img src=\"https://git.io/JLdVE\" width=\"700\"/>"],"text/plain":["<IPython.core.display.Image object>"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["! curl -O http://www.gutenberg.org/files/1268/1268-0.txt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Oxh_VQrykM_5","executionInfo":{"status":"ok","timestamp":1641609819779,"user_tz":-540,"elapsed":363,"user":{"displayName":"Hwisung Kwon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gizs2pMSWME6appADm19iw3b0G9f_CCWjKda6cL=s64","userId":"05107164275958408212"}},"outputId":"f2517863-bf1d-4aca-bbde-bcffe9de7f3a"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n","                                 Dload  Upload   Total   Spent    Left  Speed\n","\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n"]}]},{"cell_type":"code","source":["#텍스트 읽고 전처리\n","with open('1268-0.txt', 'r', encoding='UTF8') as fp:\n","    text=fp.read()\n","    \n","start_indx = text.find('THE MYSTERIOUS ISLAND')\n","end_indx = text.find('End of the Project Gutenberg')\n","print(start_indx, end_indx)\n","\n","text = text[start_indx:end_indx]\n","char_set = set(text)\n","print('전체 길이:', len(text))\n","print('고유한 문자:', len(char_set))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ILavldxWkQDj","executionInfo":{"status":"ok","timestamp":1641610194872,"user_tz":-540,"elapsed":775,"user":{"displayName":"Hwisung Kwon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gizs2pMSWME6appADm19iw3b0G9f_CCWjKda6cL=s64","userId":"05107164275958408212"}},"outputId":"ef26009a-9fd6-4b62-feda-975538a58e37"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["566 1112916\n","전체 길이: 1112350\n","고유한 문자: 80\n"]}]},{"cell_type":"markdown","source":["텍스트를 내려받고 전처리하여 총 111만 2,350개의 문자와 80개의 고유한 문자로 구성된 시퀀스를 얻었다.\n","\n","하지만 대부분 신경망 라이브러리와 RNN 구현은 문자열 형태의 입력 데이터를 다룰 수 없다.\n","\n","이 때문에 텍스트 데이터를 숫자 형태로 바꾸어야 한다.\n","\n","또한, 모델의 출력 결과를 텍스트로 변환하는 역 매핑도 필요하다.\n","\n","정수와 문자를 키와 값으로 연결한 딕셔너리로 역 매핑을 수행할 수도 있지만 인덱스와 고유 문자를 매핑한 넘파이 배열을 사용하는 것이 훨씬 효율적이다."],"metadata":{"id":"_0aHvRDsmDLy"}},{"cell_type":"code","source":["Image(url='https://git.io/JLdVz', width=700)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":286},"id":"qfHo33FtkX5c","executionInfo":{"status":"ok","timestamp":1641610411819,"user_tz":-540,"elapsed":374,"user":{"displayName":"Hwisung Kwon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gizs2pMSWME6appADm19iw3b0G9f_CCWjKda6cL=s64","userId":"05107164275958408212"}},"outputId":"47572362-037f-48c9-dd94-8637286969e3"},"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/html":["<img src=\"https://git.io/JLdVz\" width=\"700\"/>"],"text/plain":["<IPython.core.display.Image object>"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["# 문자를 정수로 매핑하는 딕셔너리를 만드는 것과 넘파이 배열의 인덱싱을 사용하여 반대로 매핑하는 예\n","chars_sorted=sorted(char_set)\n","char2int={ch:i for i,ch in enumerate(chars_sorted)}\n","char_array=np.array(chars_sorted)\n","\n","text_encoded=np.array(\n","    [char2int[ch] for ch in text],dtype=np.int32\n",")\n","\n","print('인코딩된 텍스트 크기:',text_encoded.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BKesm9U5mCN0","executionInfo":{"status":"ok","timestamp":1641610553102,"user_tz":-540,"elapsed":299,"user":{"displayName":"Hwisung Kwon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gizs2pMSWME6appADm19iw3b0G9f_CCWjKda6cL=s64","userId":"05107164275958408212"}},"outputId":"04dad4e6-5ddb-43ff-ebf9-b016b525b285"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["인코딩된 텍스트 크기: (1112350,)\n"]}]},{"cell_type":"code","source":["print(text[:15], '     == 인코딩 ==> ', text_encoded[:15])\n","print(text_encoded[15:21], ' == 디코딩 ==> ', ''.join(char_array[text_encoded[15:21]]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S6aibNDqnTIn","executionInfo":{"status":"ok","timestamp":1641610630640,"user_tz":-540,"elapsed":574,"user":{"displayName":"Hwisung Kwon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gizs2pMSWME6appADm19iw3b0G9f_CCWjKda6cL=s64","userId":"05107164275958408212"}},"outputId":"a2e1f3dd-7699-408a-b48b-a5f73963cf46"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["THE MYSTERIOUS       == 인코딩 ==>  [44 32 29  1 37 48 43 44 29 42 33 39 45 43  1]\n","[33 43 36 25 38 28]  == 디코딩 ==>  ISLAND\n"]}]},{"cell_type":"markdown","source":["넘파이 배열 text_encoded는 텍스트에 있는 모든 문자에 대한 인코딩 값을 담고 있다.\n","\n","이 배열을 이용해 텐서플로 데이터셋을 만들겠다."],"metadata":{"id":"SAffnh28nnQE"}},{"cell_type":"code","source":["import tensorflow as tf\n","\n","\n","ds_text_encoded = tf.data.Dataset.from_tensor_slices(text_encoded)\n","\n","for ex in ds_text_encoded.take(5):\n","    print('{} -> {}'.format(ex.numpy(), char_array[ex.numpy()]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Qg9REdSEoTNT","executionInfo":{"status":"ok","timestamp":1641610827069,"user_tz":-540,"elapsed":328,"user":{"displayName":"Hwisung Kwon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gizs2pMSWME6appADm19iw3b0G9f_CCWjKda6cL=s64","userId":"05107164275958408212"}},"outputId":"93a742cc-75b0-4644-de63-5dbce7919058"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["44 -> T\n","32 -> H\n","29 -> E\n","1 ->  \n","37 -> M\n"]}]},{"cell_type":"code","source":["Image(url='https://git.io/JLdVV', width=700)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":417},"id":"z5XuVanWnvTb","executionInfo":{"status":"ok","timestamp":1641610814965,"user_tz":-540,"elapsed":415,"user":{"displayName":"Hwisung Kwon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gizs2pMSWME6appADm19iw3b0G9f_CCWjKda6cL=s64","userId":"05107164275958408212"}},"outputId":"bf504b22-756b-4c72-cf7f-9a2cf6c033be"},"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/html":["<img src=\"https://git.io/JLdVV\" width=\"700\"/>"],"text/plain":["<IPython.core.display.Image object>"]},"metadata":{},"execution_count":19}]},{"cell_type":"markdown","source":["텍스트 생성 모델을 구현하기 위해 먼저 시퀀스 길이를 40으로 자르겠다.\n","\n","시퀀스 길이는 생성된 텍스트의 품질에 영향을 미친다.\n","\n","긴 시퀀스가 더 의미 있는 문장을 만들 수 있다.\n","\n","하지만, 짧은 시퀀스일 경우 모델이 대부분 문맥을 무시하고 개별 단어를 정확히 감지하는 게 초점을 맞출 수 있다.\n","\n","긴 시퀀스가 보통 더 의미 있는 문장을 만들지만 긴 시퀀스에서 RNN 모델이 장기간 의존성을 감지하기 어렵다.\n","\n","실제로 적절한 시퀀스 길이를 찾는 것은 경험적으로 평가해야 하는 하이퍼파라미터 최적화 문제이다.\n","\n","배치 크기를 41로 하여 처음 40개의 원소는 입력 마지막 40개는 타겟으로 하겠다."],"metadata":{"id":"yStJTe2soSId"}},{"cell_type":"code","source":["seq_length=40\n","chunk_size=seq_length+1\n","ds_chunks=ds_text_encoded.batch(chunk_size,drop_remainder=True)\n","\n","def split_input_target(chunk):\n","  input_seq=chunk[:-1]\n","  target_seq=chunk[1:]\n","  return input_seq,target_seq\n","\n","ds_sequences=ds_chunks.map(split_input_target)"],"metadata":{"id":"OJ6g5zNi1GP9","executionInfo":{"status":"ok","timestamp":1641614469435,"user_tz":-540,"elapsed":279,"user":{"displayName":"Hwisung Kwon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gizs2pMSWME6appADm19iw3b0G9f_CCWjKda6cL=s64","userId":"05107164275958408212"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["#몇 개의 샘플을 확인해보겠다.\n","for example in ds_sequences.take(2):\n","    print('입력 (x):', repr(''.join(char_array[example[0].numpy()])))\n","    print('타깃 (y):', repr(''.join(char_array[example[1].numpy()])))\n","    print()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Yobsi1mv2OaD","executionInfo":{"status":"ok","timestamp":1641614533674,"user_tz":-540,"elapsed":269,"user":{"displayName":"Hwisung Kwon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gizs2pMSWME6appADm19iw3b0G9f_CCWjKda6cL=s64","userId":"05107164275958408212"}},"outputId":"cd8c5496-5a47-4d97-b9bf-0c895a5c3ef0"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["입력 (x): 'THE MYSTERIOUS ISLAND ***\\n\\n\\n\\n\\nProduced b'\n","타깃 (y): 'HE MYSTERIOUS ISLAND ***\\n\\n\\n\\n\\nProduced by'\n","\n","입력 (x): ' Anthony Matonak, and Trevor Carlson\\n\\n\\n\\n'\n","타깃 (y): 'Anthony Matonak, and Trevor Carlson\\n\\n\\n\\n\\n'\n","\n"]}]},{"cell_type":"code","source":["#미니배치 만들기\n","BATCH_SIZE=64\n","BUFFER_SIZE=10000\n","ds=ds_sequences.shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"],"metadata":{"id":"rpKXE8_e2l5N","executionInfo":{"status":"ok","timestamp":1641614601117,"user_tz":-540,"elapsed":280,"user":{"displayName":"Hwisung Kwon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gizs2pMSWME6appADm19iw3b0G9f_CCWjKda6cL=s64","userId":"05107164275958408212"}}},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":["문자 수준의 모델 만들기"],"metadata":{"id":"7jnuMXmY2ujp"}},{"cell_type":"code","source":["def build_model(vocab_size, embedding_dim, rnn_units):\n","    model = tf.keras.Sequential([\n","        tf.keras.layers.Embedding(vocab_size, embedding_dim),\n","        tf.keras.layers.LSTM(\n","            rnn_units, return_sequences=True),\n","        tf.keras.layers.Dense(vocab_size)\n","    ])\n","    return model\n"],"metadata":{"id":"QBGbUxyt2xVq","executionInfo":{"status":"ok","timestamp":1641614730837,"user_tz":-540,"elapsed":394,"user":{"displayName":"Hwisung Kwon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gizs2pMSWME6appADm19iw3b0G9f_CCWjKda6cL=s64","userId":"05107164275958408212"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["charset_size = len(char_array)\n","embedding_dim = 256\n","rnn_units = 512\n","\n","tf.random.set_seed(1)\n","\n","model = build_model(\n","    vocab_size = charset_size,\n","    embedding_dim=embedding_dim,\n","    rnn_units=rnn_units)\n","\n","model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gK2GAGeP3On6","executionInfo":{"status":"ok","timestamp":1641614742877,"user_tz":-540,"elapsed":440,"user":{"displayName":"Hwisung Kwon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gizs2pMSWME6appADm19iw3b0G9f_CCWjKda6cL=s64","userId":"05107164275958408212"}},"outputId":"a6119664-8d87-47ed-ebb3-904e9ff332b3"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," embedding (Embedding)       (None, None, 256)         20480     \n","                                                                 \n"," lstm (LSTM)                 (None, None, 512)         1574912   \n","                                                                 \n"," dense (Dense)               (None, None, 80)          41040     \n","                                                                 \n","=================================================================\n","Total params: 1,636,432\n","Trainable params: 1,636,432\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"markdown","source":["LSTM 층의 출력크기는 (None,None,512)로 랭크 3이다.\n","\n","첫 번째 차원은 배치 차원이다.\n","\n","두 번째 차원은 출력 시퀀스 길이고 마지막 차원은 은닉 유닛의 개수이다.\n","\n","랭크 3의 출력을 만드는 이유는 LSTM 층을 만들 때 return_sequences=True로 지정했기 때문에\n","\n","마지막 완전 연결 층을 activation=None으로 설정했다.\n","\n","새로운 텍스트를 생성하기 위해 모델 예측 값에서 샘플링할 수 있도록 로짓 출력이 필요하기 때문에"],"metadata":{"id":"SYeHN1S53Vrm"}},{"cell_type":"code","source":["model.compile(\n","    optimizer='adam', \n","    loss=tf.keras.losses.SparseCategoricalCrossentropy(\n","        from_logits=True\n","    ))\n","\n","model.fit(ds, epochs=1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FakkLkHH4r2b","executionInfo":{"status":"ok","timestamp":1641615540347,"user_tz":-540,"elapsed":377656,"user":{"displayName":"Hwisung Kwon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gizs2pMSWME6appADm19iw3b0G9f_CCWjKda6cL=s64","userId":"05107164275958408212"}},"outputId":"4ef5f116-0511-47f2-a3b6-28a3b621aa53"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["424/424 [==============================] - 377s 883ms/step - loss: 2.1315\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f5934e560d0>"]},"metadata":{},"execution_count":27}]},{"cell_type":"markdown","source":["평가 단계\n","\n","이전 절에서 훈련한 RNN 모델은 각 문자에 대해 80개 크기의 로짓을 반환한다.\n","\n","소프트맥스 함수를 사용해서 이 로짓을 쉽게 확률로 바꿀 수 있다.\n","\n","이 확률을 사용하여 어떤 문자가 다음에 올지 결정한다.\n","\n","간단히 가장 큰 로짓 값을 가진 우너소를 선택할 수 있다.\n","\n","하지만 이 대신 출력에서 샘플링하려고 한다.\n","\n","이렇게 하지 않으면 항상 동일한 텍스트를 만든다.\n","\n","텐서플로에서 제공하는 tf.random.categorical 함수를 사용하여 범주형 분포에서 랜덤하게 샘플링할 수 있다.\n","\n","입력 로짓이 [1,1,1]일 때 세 개의 범주 [0,1,2]에서 랜덤하게 샘플링 해보겠다."],"metadata":{"id":"k_Vi9Iyf4sIa"}},{"cell_type":"code","source":["tf.random.set_seed(1)\n","logits=[[1.0,1.0,1.0,]]\n","print('확률:', tf.math.softmax(logits).numpy()[0])\n","\n","samples=tf.random.categorical(logits=logits,num_samples=10)\n","\n","tf.print(samples.numpy())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"D6pssSKj5T9C","executionInfo":{"status":"ok","timestamp":1641615733776,"user_tz":-540,"elapsed":337,"user":{"displayName":"Hwisung Kwon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gizs2pMSWME6appADm19iw3b0G9f_CCWjKda6cL=s64","userId":"05107164275958408212"}},"outputId":"dc85f8dc-77d9-491d-e577-1750c802d4f3"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["확률: [0.33333334 0.33333334 0.33333334]\n","array([[0, 0, 1, 2, 0, 0, 0, 0, 1, 0]])\n"]}]},{"cell_type":"code","source":["tf.random.set_seed(1)\n","\n","logits = [[1.0, 1.0, 3.0]]\n","print('확률:', tf.math.softmax(logits).numpy()[0])\n","\n","samples = tf.random.categorical(\n","    logits=logits, num_samples=10)\n","tf.print(samples.numpy())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XghTv_i85jtI","executionInfo":{"status":"ok","timestamp":1641615737376,"user_tz":-540,"elapsed":336,"user":{"displayName":"Hwisung Kwon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gizs2pMSWME6appADm19iw3b0G9f_CCWjKda6cL=s64","userId":"05107164275958408212"}},"outputId":"3642a38b-94cc-4bf9-ead5-750ac246556e"},"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["확률: [0.10650698 0.10650698 0.78698605]\n","array([[2, 0, 2, 2, 2, 0, 1, 2, 2, 0]])\n"]}]},{"cell_type":"markdown","source":["로짓을 기반으로 문자를 생성할 수 있다.\n","\n"],"metadata":{"id":"7plbe4-S5n7q"}},{"cell_type":"code","source":["def sample(model, starting_str, \n","           len_generated_text=500, \n","           max_input_length=40,\n","           scale_factor=1.0):\n","    encoded_input = [char2int[s] for s in starting_str]\n","    encoded_input = tf.reshape(encoded_input, (1, -1))\n","\n","    generated_str = starting_str\n","\n","    model.reset_states()\n","    for i in range(len_generated_text):\n","        logits = model(encoded_input)\n","        logits = tf.squeeze(logits, 0)\n","\n","        scaled_logits = logits * scale_factor\n","        new_char_indx = tf.random.categorical(\n","            scaled_logits, num_samples=1)\n","        \n","        new_char_indx = tf.squeeze(new_char_indx)[-1].numpy()    \n","\n","        generated_str += str(char_array[new_char_indx])\n","        \n","        new_char_indx = tf.expand_dims([new_char_indx], 0)\n","        encoded_input = tf.concat(\n","            [encoded_input, new_char_indx],\n","            axis=1)\n","        encoded_input = encoded_input[:, -max_input_length:]\n","\n","    return generated_str\n","\n","tf.random.set_seed(1)\n","print(sample(model, starting_str='The island'))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jDrruFrV5Vz8","executionInfo":{"status":"ok","timestamp":1641615803755,"user_tz":-540,"elapsed":24267,"user":{"displayName":"Hwisung Kwon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gizs2pMSWME6appADm19iw3b0G9f_CCWjKda6cL=s64","userId":"05107164275958408212"}},"outputId":"65671fd0-fac5-4a1d-e91e-58c0cb4e40be"},"execution_count":32,"outputs":[{"output_type":"stream","name":"stdout","text":["The island hed seach a shatee of the prifters a miect carain of\n","thes issoppeeve, oncicated by lack gulon; aid recanient, hereing main the onchowed ancacimed. It with on the engarchound ithel bet, any not ming saver eprious Clicht, were basilus to the strees in netion canters of mank hist is a filler, to lengund the pablec. Hard\n","Halding,” sad the ritk” re\n","will be mornert wourd nott colmant, andly\n","apcearing.\n","\n","Heore, bet. “Anot was wirnaster, af fide.\n","Hexcrose dea, thing!” reliled the vislaby infear Midntwen\n"]}]},{"cell_type":"code","source":["#로짓의 스케일 조정하기\n","#계수를 점점 작게하면 균등해진다.\n","logits = np.array([[1.0, 1.0, 3.0]])\n","\n","print('스케일 조정 전의 확률: ', tf.math.softmax(logits).numpy()[0])\n","\n","print('0.5배 조정 후 확률:  ', tf.math.softmax(0.5*logits).numpy()[0])\n","\n","print('0.1배 조정 후 확률:  ', tf.math.softmax(0.1*logits).numpy()[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WuYRhrPF7u_A","executionInfo":{"status":"ok","timestamp":1641615937667,"user_tz":-540,"elapsed":315,"user":{"displayName":"Hwisung Kwon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gizs2pMSWME6appADm19iw3b0G9f_CCWjKda6cL=s64","userId":"05107164275958408212"}},"outputId":"42887170-e453-49b2-8008-c3216e745c7a"},"execution_count":33,"outputs":[{"output_type":"stream","name":"stdout","text":["스케일 조정 전의 확률:  [0.10650698 0.10650698 0.78698604]\n","0.5배 조정 후 확률:   [0.21194156 0.21194156 0.57611688]\n","0.1배 조정 후 확률:   [0.31042377 0.31042377 0.37915245]\n"]}]},{"cell_type":"code","source":["tf.random.set_seed(1)\n","print(sample(model, starting_str='The island', \n","             scale_factor=2.0))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nmy6dopN701k","executionInfo":{"status":"ok","timestamp":1641615970008,"user_tz":-540,"elapsed":24012,"user":{"displayName":"Hwisung Kwon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gizs2pMSWME6appADm19iw3b0G9f_CCWjKda6cL=s64","userId":"05107164275958408212"}},"outputId":"a6028531-b0f8-416f-97d3-7fc322fe1780"},"execution_count":34,"outputs":[{"output_type":"stream","name":"stdout","text":["The island of the colland the more to the ore had been frear of the corther on the reach of the conting of the sease the onger of the seach had not mad of the vester of the corbers. The will bence to the portan the corsion Harding the callanis plase the corear of the conters of the cortonce in the shouth of the sone day of the age of the said contion’s tate of the ronging to the was and the sive and it of the engineer to the the wase to the colland the sure of have had the contine of the was seas and the \n"]}]},{"cell_type":"code","source":["tf.random.set_seed(1)\n","print(sample(model, starting_str='The island', \n","             scale_factor=0.5))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fVVv014U72-S","executionInfo":{"status":"ok","timestamp":1641615997990,"user_tz":-540,"elapsed":23991,"user":{"displayName":"Hwisung Kwon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gizs2pMSWME6appADm19iw3b0G9f_CCWjKda6cL=s64","userId":"05107164275958408212"}},"outputId":"bea55a3f-5878-4d16-893d-a8b79a36a745"},"execution_count":35,"outputs":[{"output_type":"stream","name":"stdout","text":["The island eloro? Bib Nof,” rUmmtlawmmoodqhst.\n","\n","Tha qoadl Thene ourvalnys. Thy? Anklo Cyot IsmecMeces righacking Nil.,” resthoring as the mhansy.\n","\n","Al?\n","-Tapnthaweysu.\n","Helme.\n","ADo, Frxting tree Tlvalar’! Pepllot obtes! Posstad\n","ambitk thead\n","Hhicntatint; sttreis flfh. ashed it!.”\n"," ole no-Troy eur.\n","2BGiltersule. PuccCorear ., WapaIn.\n","\n","CApouctyis\n","CWoas,,evo” pr vike Nn. Yow?”.\n","“sivions,”\n","3n\n","clithlerkzg\n","3r cepperw.\n","\n","The foles,;”\n","Dusht. Mxtithivetem PeccanfStfy two.\n","\n","DN Spowarpttcle, hosighetsin.\n","“If ug na ravoun,\n"]}]},{"cell_type":"markdown","source":["# 16.4 트랜스포머 모델을 사용한 언어 이해"],"metadata":{"id":"W9_Pypo1776K"}},{"cell_type":"markdown","source":["입력과 출력 시퀀스사이에 있는 전역 의존성을 모델링할 수 있다.\n","\n","어텐션을 기반으로 하고 구체적으로는 셀프 어텐션 메커니즘을 기반으로한다."],"metadata":{"id":"WWFEw7FG7_8F"}},{"cell_type":"markdown","source":["## 16.4.1 셀프 어텐션 메커니즘 이해"],"metadata":{"id":"EcJcpY428Lof"}},{"cell_type":"markdown","source":["셀프 어텐션 기본 구조\n","\n","입력 원소에 대한 출력 시퀀스에 있는 각 원소의 의존성을 모델링하는 것이 목적이다.\n","\n","세 단계로 구성된다.\n","\n","첫째, 현재 원소와 시퀀스에 있는 다른 모든 원소 사이의 유사도를 기반으로 중요도 가중치를 계산한다.\n","\n","둘째, 소프트맥스 함수를 사용하여 이 가중치를 정규화한다.\n","\n","셋째, 가중치를 해당하는 시퀀스 원소와 결합하여 어텐션 값을 계산한다."],"metadata":{"id":"9gFS2Syj8OPG"}},{"cell_type":"code","source":["Image(url='https://git.io/JLdVo', width=700)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":348},"id":"HxksBgSt9dtx","executionInfo":{"status":"ok","timestamp":1641616374040,"user_tz":-540,"elapsed":307,"user":{"displayName":"Hwisung Kwon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gizs2pMSWME6appADm19iw3b0G9f_CCWjKda6cL=s64","userId":"05107164275958408212"}},"outputId":"abb7b5db-3386-4609-8b21-e9286e46077e"},"execution_count":36,"outputs":[{"output_type":"execute_result","data":{"text/html":["<img src=\"https://git.io/JLdVo\" width=\"700\"/>"],"text/plain":["<IPython.core.display.Image object>"]},"metadata":{},"execution_count":36}]},{"cell_type":"markdown","source":["쿼리, 키, 값 가중치를 가진 셀프 어텐션 메커니즘\n","\n","셀프 어텐션은 출력을 계산할 때 계산되는 파라미터를 전혀 사용하지 않았다.\n","\n","따라서 언어 모델을 훈련할 때 분류 오차를 최소화하는 것 같이 목적 함수를 최적화하려면 입력 원소가 되는 단어 임베딩을 바꿔야 한다.\n","\n","다르게 말해 기본적인 셀프 어텐션 메커니즘을 사용하면 트랜스포머 모델이 주어진 시퀀스에서 모델을 최적화하는 동안 어텐션 값을 바꾸거나 업데이트하는 데 제한적이다.\n","\n","셀프 어텐션 메커니즘을 모델 최적화에 대해 유연하고 적응할 수 있게 만들기 위해 추가적인 가중치 행렬을 사용하겠다."],"metadata":{"id":"_zDsfMNN9fZc"}},{"cell_type":"markdown","source":["## 16.4.2 멀티-헤드 어텐션과 트랜스포머 블록"],"metadata":{"id":"hMDpbxAv_WaH"}},{"cell_type":"markdown","source":["각 셀프 어텐션 메커니즘을 헤드라고 부르며 병렬로 계산할 수 있다.\n","\n","r개의 병렬 헤드를 사용하여 각 헤드는 크기가 m인 벡터 h를 만든다. \n","\n","이 벡터를 연결하여 크기가 r x m인 z를 얻는다.\n","\n","마지막으로 이 연결된 벡터와 출력 행렬을 점곱하여 다음과 같이 최종 출력을 만든다."],"metadata":{"id":"xvTWics8_ehS"}},{"cell_type":"code","source":["Image(url='https://git.io/JLdV6', width=700)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":277},"id":"bypZE3oh_0gS","executionInfo":{"status":"ok","timestamp":1641616988414,"user_tz":-540,"elapsed":431,"user":{"displayName":"Hwisung Kwon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gizs2pMSWME6appADm19iw3b0G9f_CCWjKda6cL=s64","userId":"05107164275958408212"}},"outputId":"2171216d-478b-47f0-d006-13c6bb7d9ff7"},"execution_count":37,"outputs":[{"output_type":"execute_result","data":{"text/html":["<img src=\"https://git.io/JLdV6\" width=\"700\"/>"],"text/plain":["<IPython.core.display.Image object>"]},"metadata":{},"execution_count":37}]},{"cell_type":"markdown","source":["아직 언급하지 않은 두 가지 구성 요소가 추가되어 있다.\n","\n","이 중 하나는 잔차 연결이다.\n","\n","층의 출력을 입력에 더한다.\n","\n","잔차 연결로 층을 구성하는 블록을 잔차 블록이라고 한다.\n","\n","다른 하나는 층 정규화이다.\n","\n","각 층에서 신경망의 입력과 활성화 출력을 정규화 또는 스케일을 조정하는 고급 방법이다.\n","\n","동작 방식에 대해 말해보면\n","\n","먼저 입력 시퀀스가 앞서 언급한 셀프 어텐션 메커니즘을 기반으로 하는 MHA 층으로 전달된다.\n","\n","또한 입력 시퀀스가 잔차 연결을 통해 MHA 층의 출력에 더해진다.\n","\n","이렇게 하면 훈련하는 동안 앞쪽의 층이 충분한 그레이디언트 신호를 받게 된다.\n","\n","훈련 속도와 수렴을 향상시키기 위해 자주 사용되는 기법이다.\n","\n","입력 시퀀스가 MHA 층의 출력에 더해진 후 이 출력이 층 정규화를 통해 정규화된다.\n","\n","정규화된 신호가 연속된 MLP 층과 잔차 연결을 통과한다.\n","\n","마지막으로 잔차 블록의 출력을 다시 정규화하여 출력 시퀀스로 반환한다.\n"],"metadata":{"id":"MId6nI-b_1Uh"}}]}